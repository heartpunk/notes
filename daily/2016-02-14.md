# 2016-02-14

## Overview

I haven't done this for a couple of weeks now, but I'm getting back to it finally. Today was valentines day, and I spent it doing random ass shit, sort of like I normally do. I did some reading and OH MY GOD intense bursts of amusing facebooking, went on a walk in the park (prospect park is SO beautiful right now, if cold), browsed around the Park Slope Barnes and Noble, which was suprisingly pleasant. I forgot how nice real bookstores can be, and I kind of want to go back to them more often. I likely won't, but we'll see. I may try to make it a bit of a priority. On the way to the bookstore, and a bit before and after, I was listening to The Phoenix Project, which is mind blowingly good in its subject area. Or, at least it really hits close to home. Too many bits of it are way too close to things that have already happened in my still relatively short career. After that I read some blog posts out of my feedly, including one on [ramcloud](http://blog.acolyer.org/2016/01/18/ramcloud/), which is just amazingly awesome. More on it in the notes.

## Notes
- Phoenix Project
  - Breaks down four types of work (in the context of IT):
    # business project work
    # internal project work
    # change work
    # unplanned work
  - Emphasizes the importance of minimizing unplanned work.
  - Introduces the concept of a constraint, i.e. the part of the organization or system that is the bounding factor in the amount of work that can be done. definitionally there is always at least one of these (and almost always exactly one). Also emphasizes the importance of planning around the constraint, and only letting work into the system only as the constraint can process it, but also never leaving the constraint idle. This all makes good sense, while not seeming tremendously insightful (though it clearly actually is).
  - The relationship between unplanned work and the constraint is interesting. Unplanned work is done under higher pressure, often enough, or with lower oversight, even if it's done without time pressure. This work tends to be of lower quality. Unplanned work is done because the constraint is tied up, and so the work can't get time on the schedule. However, since unplanned work tends to increase the fragility of the system as a whole, it quickly ends up dominating the workload of the entire organization.
  - Interesting analogy made between unplanned work and dark matter - you often only see unplanned work as a result of the work it displaces. There's a nice bit about how "phoenix is going to clear the calendar", i.e., knock every other bit of planned work out of the way, once it goes badly enough.
- [The RAMCloud Storage System](http://blog.acolyer.org/2016/01/18/ramcloud/) is a wonderful, wonderful paper. I only read the summary, but as the original is 55 pages, I am well more than comfortable with that.
  - The implementation details are cool, but I think dramatically less cool than the higher level points made at the end, so I'll at least initially focus on those.
  - There's a really interesting point as to why we even need this thing. The scale of computation required for a city full of self driving cars is sufficient to warrant latencies at the scale they've managed (7-15 microseconds per operation).
  - Another interesting point is that applications as data intensive as Facebook, for an example, might become dramatically easier to write with very high throughput storage systems like this.
  - The approach to fault tolerance is rather erlang-ish. They either handle errors at the client entirely, via retries, etc., or they do what they call "failure promotion", and just restart the whole dang node.
  - Lessons learned:
    - Layers cause latency. This is obvious, but for their goals they really had to take this to heart and avoid using layers at all costs. They took two approaches:
      # Figure out the theoretical optimum performance by some method or another, and see if there's a modularization, rather than layering, that accomplishes that or something close to it.
      # If you must layer, build a happy path that executes very quickly and skips most layers.
    - Randomization is a very useful tool for building distributed systems. I kinda grokked this already, but it's nice to see it emphasized elsewhere.
    - Retrying is also powerful.
    - Use rule based rather than [zero-state-assuming](http://www.ribbonfarm.com/2014/10/29/crash-only-thinking/) techniques for building what they call DCFTs, or Distributed, Concurrent, Fault-Tolerant systems. They have [another paper on this](http://blog.acolyer.org/2016/01/19/dcft/). Haven't read that one yet, but really, really looking forward to it.
- Used [this little gist](https://gist.github.com/ljos/3019549) and [this issue](https://bitbucket.org/ronaldoussoren/pyobjc/issues/137/symbol-not-found-_pyobject_repr-on-python#comment-None) to establish how easy reading keystrokes on osx is. Turns out, pretty easy! So, I'm going to build off that info to make a tracker for which keyboard I'm using, and which keycombos I'm hitting most, to monitor my RSI-causing-things. This of course won't cover phone usage, but I found [an](https://inthemoment.io/) [app](https://bitbucket.org/ronaldoussoren/pyobjc/issues/137/symbol-not-found-_pyobject_repr-on-python#comment-None) that at least counts that in some rough way. Oh, apparently it supports time limits too! This is great. This is what I need. So, RSI plan is complete! Whooooo.
